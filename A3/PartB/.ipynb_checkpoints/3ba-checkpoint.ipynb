{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 785\n",
    "r = 26\n",
    "layers = [1]\n",
    "M = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6500, 785)\n"
     ]
    }
   ],
   "source": [
    "file = open('train.csv')\n",
    "file_reader = csv.reader(file)\n",
    "X_train = []\n",
    "for i in range(0, n):\n",
    "    X_train.append([])\n",
    "for row in file_reader:\n",
    "    X_train[0].append(1.0)\n",
    "    for i in range(n-1):\n",
    "        X_train[i+1].append(float(row[i]))\n",
    "X_train = np.array(X_train)\n",
    "X_train = X_train.T/255\n",
    "Y_train = np.zeros((len(X_train), r))\n",
    "file = open('train.csv')\n",
    "file_reader = csv.reader(file)\n",
    "count = 0\n",
    "for row in file_reader:\n",
    "    Y_train[count][int(row[n-1])] = 1\n",
    "    count += 1\n",
    "    \n",
    "file = open('test.csv')\n",
    "file_reader = csv.reader(file)\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for i in range(0, n):\n",
    "    X_test.append([])\n",
    "for row in file_reader:\n",
    "    X_test[0].append(1.0)\n",
    "    for i in range(n-1):\n",
    "        X_test[i+1].append(float(row[i]))\n",
    "    Y_test.append(int(row[n-1]))\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.T/255\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.append(r)\n",
    "Theta_dict = {}\n",
    "Theta_dict[0] = np.random.randn(layers[0], n)*(np.sqrt(2/n))\n",
    "for i in range(1, len(layers)):\n",
    "    Theta_dict[i] = np.random.randn(layers[i], layers[i-1]+1)*(np.sqrt(2/(layers[i-1]+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-1*x))\n",
    "\n",
    "def calc_output(Theta_dict, X):\n",
    "    O_dict = {}\n",
    "    O_dict[0] = np.insert(sigmoid(np.dot(X, (Theta_dict[0]).T)), 0, 1, axis=1)\n",
    "    for i in range(1, len(layers)):\n",
    "        O_dict[i] = sigmoid(np.dot(O_dict[i-1], (Theta_dict[i]).T))\n",
    "        if(i!=len(layers)-1):\n",
    "            O_dict[i] = np.insert(O_dict[i], 0, 1, axis=1)\n",
    "    return O_dict\n",
    "\n",
    "def calc_gradient(Theta_dict, Y, X):\n",
    "    gradient = {}\n",
    "    Delta = {}\n",
    "    O_dict = calc_output(Theta_dict, X)\n",
    "    #output layer\n",
    "    O = O_dict[len(layers)-1]\n",
    "    Delta_j = np.multiply(np.multiply((Y-O), O), (1-O))\n",
    "    O_prev = O_dict[len(layers)-2]\n",
    "    gradient[len(layers)-1] = -np.matmul(Delta_j.T, O_prev)/M\n",
    "    Delta[len(layers)-1] = Delta_j\n",
    "    for j in range(len(layers)-2, -1, -1):\n",
    "        O_j = O_dict[j]\n",
    "        O_j_prev = X\n",
    "        if(j!=0):\n",
    "            O_j_prev = O_dict[j-1]\n",
    "        Delta_j = np.dot(Delta[j+1], Theta_dict[j+1])\n",
    "        Delta_j = np.multiply(np.multiply(Delta_j, O_j), (1-O_j))\n",
    "        Delta_j = Delta_j[:, 1:]\n",
    "        gradient[j] = -np.matmul(Delta_j.T, O_j_prev)/M\n",
    "    return gradient\n",
    "\n",
    "def one_step(Theta_dict, Y, X, eta):\n",
    "    gradient = calc_gradient(Theta_dict, Y, X)\n",
    "    for i in range(0, len(layers)):\n",
    "        Theta_dict[i] = Theta_dict[i] - (eta*gradient[i])\n",
    "\n",
    "def calc_J(Theta_dict, Y, X):\n",
    "    O_dict = calc_output(Theta_dict, X)\n",
    "    O = O_dict[len(layers)-1]\n",
    "    O = np.multiply((Y-O), (Y-O))\n",
    "    O /= (2*len(Y))\n",
    "    return np.sum(O)\n",
    "\n",
    "def accuracy(Y, X, Theta_dict):\n",
    "    O = calc_output(Theta_dict, X)[len(layers)-1]\n",
    "    ans = np.argmax(O, axis=1)\n",
    "    ans = Y-ans\n",
    "    ans = ans[ans==0]\n",
    "    return len(ans)/len(Y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1379251480102539 2 247.51727535191782 10 3.8461538461538463\n",
      "0.2704019546508789 3 92.8795444466842 247.51727535191782 3.8461538461538463\n",
      "0.3928260803222656 4 73.97589678806919 92.8795444466842 3.8461538461538463\n",
      "0.5062780380249023 5 69.14695384976298 73.97589678806919 3.8461538461538463\n",
      "0.6386458873748779 6 66.9297541170719 69.14695384976298 3.8461538461538463\n",
      "0.7724320888519287 7 65.68333386228966 66.9297541170719 3.8461538461538463\n",
      "0.9374630451202393 8 64.90024101330744 65.68333386228966 3.8461538461538463\n",
      "1.0791020393371582 9 64.37154536831103 64.90024101330744 3.8461538461538463\n",
      "1.226283073425293 10 63.99602156129502 64.37154536831103 3.8461538461538463\n",
      "1.3390920162200928 11 63.719006671421326 63.99602156129502 3.8461538461538463\n",
      "1.497992992401123 12 63.50857354171123 63.719006671421326 3.8461538461538463\n",
      "1.6427290439605713 13 63.34492739088976 63.50857354171123 3.8461538461538463\n",
      "1.7929110527038574 14 63.21520374464062 63.34492739088976 3.8461538461538463\n",
      "1.9375109672546387 15 63.11071683458676 63.21520374464062 3.8461538461538463\n",
      "2.1017560958862305 16 63.025414029571685 63.11071683458676 3.8461538461538463\n",
      "2.2308120727539062 17 62.95496389821377 63.025414029571685 3.8461538461538463\n",
      "2.3624539375305176 18 62.89619554694478 62.95496389821377 3.8461538461538463\n",
      "2.4938418865203857 19 62.846741675603496 62.89619554694478 3.8461538461538463\n",
      "2.638543128967285 20 62.80480439955568 62.846741675603496 3.8461538461538463\n",
      "2.760686159133911 21 62.7689975464532 62.80480439955568 3.8461538461538463\n",
      "2.880188226699829 22 62.73823798779799 62.7689975464532 3.8461538461538463\n",
      "2.998927116394043 23 62.711669221344316 62.73823798779799 3.8461538461538463\n",
      "3.1195881366729736 24 62.688606649756196 62.711669221344316 3.8461538461538463\n",
      "3.238862991333008 25 62.668497752687685 62.688606649756196 3.8461538461538463\n",
      "3.3659801483154297 26 62.65089266976593 62.668497752687685 3.8461538461538463\n",
      "3.4780750274658203 27 62.635422181541486 62.65089266976593 3.8461538461538463\n",
      "3.5921242237091064 28 62.6217810264548 62.635422181541486 3.8461538461538463\n",
      "3.7162930965423584 29 62.609715119361084 62.6217810264548 3.8461538461538463\n",
      "3.854278087615967 30 62.59901165862358 62.609715119361084 3.8461538461538463\n",
      "4.002610921859741 31 62.5894913965078 62.59901165862358 3.8461538461538463\n",
      "4.126090049743652 32 62.58100254698831 62.5894913965078 3.8461538461538463\n",
      "4.248795032501221 33 62.57341594515266 62.58100254698831 3.8461538461538463\n",
      "4.378436088562012 34 62.56662117206462 62.57341594515266 3.8461538461538463\n",
      "4.500683069229126 35 62.56052343071634 62.56662117206462 3.8461538461538463\n",
      "4.618324041366577 36 62.55504101095054 62.56052343071634 3.8461538461538463\n",
      "4.72960090637207 37 62.55010321966683 62.55504101095054 3.8461538461538463\n",
      "4.843067169189453 38 62.54564868116354 62.55010321966683 3.8461538461538463\n",
      "4.966815948486328 39 62.54162393385802 62.54564868116354 3.8461538461538463\n",
      "5.084542989730835 40 62.53798226578733 62.54162393385802 3.8461538461538463\n",
      "5.196337938308716 41 62.534682743606076 62.53798226578733 3.8461538461538463\n",
      "5.349854946136475 42 62.53168939924531 62.534682743606076 3.8461538461538463\n",
      "5.466387033462524 43 62.528970545702016 62.53168939924531 3.8461538461538463\n",
      "5.586714029312134 44 62.526498199110776 62.528970545702016 3.8461538461538463\n",
      "5.727643013000488 45 62.52424758870168 62.526498199110776 3.8461538461538463\n",
      "5.848489999771118 46 62.522196739753056 62.52424758870168 3.8461538461538463\n",
      "5.99695611000061 47 62.520326117427686 62.522196739753056 3.8461538461538463\n",
      "6.129754066467285 48 62.51861832159354 62.520326117427686 3.8461538461538463\n",
      "6.242743015289307 49 62.5170578245031 62.51861832159354 3.8461538461538463\n",
      "6.391759157180786 50 62.51563074463202 62.5170578245031 3.8461538461538463\n",
      "6.520018815994263 51 62.514324651130934 62.51563074463202 3.8461538461538463\n",
      "6.639024019241333 52 62.51312839428165 62.514324651130934 3.8461538461538463\n",
      "6.785009145736694 53 62.51203195811251 62.51312839428165 3.8461538461538463\n",
      "6.912440061569214 54 62.511026331955186 62.51203195811251 3.8461538461538463\n",
      "7.021322011947632 55 62.5101033982379 62.511026331955186 3.8461538461538463\n"
     ]
    }
   ],
   "source": [
    "b = 1\n",
    "epochs = 1\n",
    "eta = 0.1\n",
    "\n",
    "J_old = 0\n",
    "J_new = 10\n",
    "\n",
    "start = time.time()\n",
    "while(abs(J_new-J_old) > 0.001 and epochs<1000):\n",
    "    b = 1\n",
    "    J_old = J_new\n",
    "    J_new = 0.0\n",
    "    while(b*M <= len(Y_train)):\n",
    "        X = X_train[((b-1)*M):(b*M)]\n",
    "        Y = Y_train[((b-1)*M):(b*M)]\n",
    "        one_step(Theta_dict, Y, X, eta)\n",
    "        b += 1\n",
    "        J_new += calc_J(Theta_dict, Y, X)\n",
    "    epochs += 1\n",
    "    print(time.time()-start, epochs, J_new, J_old, accuracy(Y_test, X_test, Theta_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12317 683 0.9474615384615385\n"
     ]
    }
   ],
   "source": [
    "#acccuracy\n",
    "file = open('train.csv')\n",
    "file_reader = csv.reader(file)\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for i in range(0, n):\n",
    "    X_test.append([])\n",
    "for row in file_reader:\n",
    "    X_test[0].append(1.0)\n",
    "    for r in range(n-1):\n",
    "        X_test[r+1].append(float(row[r]))\n",
    "    Y_test.append(int(row[n-1]))\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.T\n",
    "    \n",
    "O = calc_output(Theta_dict, X_test)[len(layers)-1]\n",
    "correct = 0.0\n",
    "incorrect = 0.0\n",
    "ans = np.argmax(O, axis=1)\n",
    "ans = Y_test-ans\n",
    "ans = ans[ans==0]\n",
    "print(len(ans), len(Y_test)-len(ans), len(ans)/len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 785)\n"
     ]
    }
   ],
   "source": [
    "print(Theta_dict[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 26) (26, 251)\n"
     ]
    }
   ],
   "source": [
    "grad = calc_gradient(Theta_dict, Y_train[0:15], X_train[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 785)\n"
     ]
    }
   ],
   "source": [
    "print(grad[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
